
  0%|                                                                                                                                                                                                               | 0/60 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
{'loss': 2.041, 'grad_norm': 0.7058355808258057, 'learning_rate': 4e-05, 'epoch': 0.0}

  3%|██████▌                                                                                                                                                                                              | 2/60 [02:21<1:08:02, 70.39s/it]
{'loss': 1.951, 'grad_norm': 0.6944906711578369, 'learning_rate': 8e-05, 'epoch': 0.0}

  5%|█████████▉                                                                                                                                                                                             | 3/60 [03:16<59:48, 62.95s/it]

  7%|█████████████▏                                                                                                                                                                                       | 4/60 [04:27<1:01:54, 66.33s/it]

  8%|████████████████▍                                                                                                                                                                                    | 5/60 [05:57<1:08:43, 74.97s/it]

 10%|███████████████████▉                                                                                                                                                                                   | 6/60 [06:37<56:31, 62.80s/it]

 12%|███████████████████████▏                                                                                                                                                                               | 7/60 [07:26<51:39, 58.48s/it]

 13%|██████████████████████████▌                                                                                                                                                                            | 8/60 [08:18<48:58, 56.50s/it]

 15%|█████████████████████████████▊                                                                                                                                                                         | 9/60 [09:03<44:44, 52.64s/it]

 17%|█████████████████████████████████                                                                                                                                                                     | 10/60 [10:30<52:54, 63.50s/it]

 18%|████████████████████████████████████▎                                                                                                                                                                 | 11/60 [11:05<44:32, 54.54s/it]

 20%|███████████████████████████████████████▌                                                                                                                                                              | 12/60 [12:10<46:21, 57.96s/it]

 22%|██████████████████████████████████████████▉                                                                                                                                                           | 13/60 [13:02<43:49, 55.95s/it]

 23%|██████████████████████████████████████████████▏                                                                                                                                                       | 14/60 [13:49<40:53, 53.34s/it]


 27%|████████████████████████████████████████████████████▊                                                                                                                                                 | 16/60 [14:44<30:21, 41.40s/it]
{'loss': 1.5202, 'grad_norm': 1.0446609258651733, 'learning_rate': 0.00016, 'epoch': 0.01}

 28%|████████████████████████████████████████████████████████                                                                                                                                              | 17/60 [15:25<29:33, 41.25s/it]

 30%|███████████████████████████████████████████████████████████▍                                                                                                                                          | 18/60 [16:10<29:40, 42.38s/it]

 32%|██████████████████████████████████████████████████████████████▋                                                                                                                                       | 19/60 [17:09<32:26, 47.47s/it]

 33%|██████████████████████████████████████████████████████████████████                                                                                                                                    | 20/60 [18:10<34:23, 51.58s/it]

 35%|█████████████████████████████████████████████████████████████████████▎                                                                                                                                | 21/60 [18:59<32:54, 50.64s/it]

 37%|████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 22/60 [19:53<32:52, 51.91s/it]

 38%|███████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 23/60 [22:47<54:36, 88.54s/it]

 40%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 24/60 [23:01<39:42, 66.19s/it]

 42%|██████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 25/60 [23:37<33:12, 56.93s/it]


 45%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                             | 27/60 [26:02<35:40, 64.87s/it]
{'loss': 1.3994, 'grad_norm': 1.2312346696853638, 'learning_rate': 0.00012, 'epoch': 0.01}


 48%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 29/60 [28:00<30:31, 59.09s/it]
{'loss': 1.434, 'grad_norm': 1.2831486463546753, 'learning_rate': 0.00011272727272727272, 'epoch': 0.01}

 50%|███████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 30/60 [29:10<31:15, 62.50s/it]

 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 31/60 [29:58<27:59, 57.90s/it]

 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                            | 32/60 [30:53<26:42, 57.24s/it]

 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                         | 33/60 [31:51<25:49, 57.40s/it]

 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                     | 34/60 [32:50<25:06, 57.93s/it]

 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 35/60 [34:43<31:01, 74.47s/it]

 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 36/60 [36:22<32:38, 81.62s/it]

 62%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 37/60 [38:56<39:38, 103.43s/it]

 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 38/60 [40:00<33:33, 91.51s/it]

 65%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                     | 39/60 [40:48<27:30, 78.59s/it]

 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 40/60 [41:46<24:06, 72.32s/it]

 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 41/60 [44:53<33:48, 106.77s/it]

 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 42/60 [45:39<26:31, 88.41s/it]

 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 43/60 [46:55<24:03, 84.93s/it]

 73%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 44/60 [47:59<20:55, 78.47s/it]

 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 45/60 [49:13<19:18, 77.24s/it]

 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                              | 46/60 [50:02<16:02, 68.78s/it]

 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 47/60 [50:57<13:59, 64.57s/it]

 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                       | 48/60 [52:20<14:00, 70.03s/it]

 82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 49/60 [52:44<10:18, 56.25s/it]

 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 50/60 [53:39<09:18, 55.88s/it]

 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 51/60 [54:26<08:00, 53.42s/it]

 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                          | 52/60 [55:14<06:53, 51.71s/it]


 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                   | 54/60 [58:49<07:36, 76.12s/it]
{'loss': 1.1375, 'grad_norm': 1.280605673789978, 'learning_rate': 2.1818181818181818e-05, 'epoch': 0.03}

 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                | 55/60 [59:11<04:59, 59.81s/it]

 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 56/60 [1:00:05<03:53, 58.27s/it]

 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 57/60 [1:01:03<02:54, 58.14s/it]

 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 58/60 [1:06:29<04:37, 138.50s/it]

 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 59/60 [1:07:40<01:58, 118.18s/it]

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [1:08:04<00:00, 90.04s/it]
{'train_runtime': 4089.2177, 'train_samples_per_second': 0.117, 'train_steps_per_second': 0.015, 'train_loss': 1.4229595720767976, 'epoch': 0.03}
<|begin_of_text|>### Question: What is (are) Parasites - Scabies?
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [1:08:06<00:00, 68.11s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Traceback (most recent call last):
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_LoRA.py", line 133, in <module>
    main()
  File "c:\Users\pink\Documents\Study\Intelligent Systems\COS30018-Mitigate-Hallucination\Finetuning\LLAMA3_LoRA.py", line 128, in main
    output_tokens = model.generate(**input_tokens, streamer=streamer, max_new_tokens=100, do_sample=True, top_p=0.8)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\peft_model.py", line 1638, in generate
    outputs = self.base_model.generate(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\generation\utils.py", line 2024, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\generation\utils.py", line 2982, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 1189, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 989, in forward
    layer_outputs = self._gradient_checkpointing_func(
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\_compile.py", line 31, in inner
    return disable_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\_dynamo\eval_frame.py", line 600, in _fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\utils\checkpoint.py", line 481, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\autograd\function.py", line 574, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\utils\checkpoint.py", line 255, in forward
    outputs = run_function(*args)
              ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
                                                          ^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\transformers\models\llama\modeling_llama.py", line 617, in forward
    query_states = self.q_proj(hidden_states)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\peft\tuners\lora\layer.py", line 544, in forward
    result = self.base_layer(x, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\pink\anaconda3\envs\LLama3-hallucinate\Lib\site-packages\torch\nn\modules\linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: expected mat1 and mat2 to have the same dtype, but got: float != struct c10::BFloat16